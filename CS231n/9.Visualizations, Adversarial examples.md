# Visualizations
CNN이 어떻게 좋은 성능을 내는지 확인하기 위해 Visualizations을 이용하여 들여다 본다. 
CNN이 좋은 성능을 내는 것은 알고 있는데 이게 어떻게 이런 성능을 내는지는 여전히 blackbox인 경우가 많다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/e6836d8b-a1c4-480b-ac3f-569c28b4cb01" height="90%" width="90%"></p>

CNN이 무엇을 하는지 알아내는 가장 간단한 방법은 row activation을 살펴보는 것이다. 하나의 뉴런을 activation하게 하는 부분을 시각화 하는 것인데 위 사진을 보면 pool5 layer에서 임의의 뉴런을 취한 다음에 여러 장의 이미지를 학습시킨 것이다. 
그러면 이 임의의 뉴런을 가장 excite시키는 것이 어떤 것인지 알 수 있는데 사진의 각 행이 하나의 뉴런에 매치한다고 볼 수 있다. 
예를 들어 1행의 뉴런을 보면 사람 사진에 대해 반응한 것이고, 4행 뉴런을 보면 text에 반응한 것이다.

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/67567942-7936-49b4-9613-be6e785179c5" height="90%" width="90%"></p>

두 번째 방법은 Filter(Kernel)를 visualize한 방법이다. 위 사진은 gabor filter로 특정 외곽선의 방향과 같은 것을 검출하는 필터이다. 
예를 들어 conv1 layer의 filter들에 대해 시각화 하면 위 사진과 같이 나오고, 여기서 이미지에 직접 작용하는 filter는 
첫 번째 conv에 있는 filter라고 할 수 있다.   

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/6488d5cd-f7fb-4f21-a13f-7e23b5e8c453" height="90%" width="90%"></p>

첫 번째 layer가 아닌 그 다음 layer들의 weight들은 visualize를 할 수는 있지만 raw이미지에 대한 것이 아니라 전 단계의 activation
에 대한 visualize이기 때문에 해석하기가 쉽지는 않다. 의미가 크지 않다고 할 수 있다. layer 2부터 괄호 안에 있는 이미지 묶음이
하나의 filter에 대응하는 것이라 볼 수 있다. 


세 번째 방법은 representation 자체를 visualize하는 것이다. classification직전의 layer인 fc7 layer에 이미지에 대한 
4096차원의 코드가 들어있다고 볼 수 있고, 이 각각의 코드들을 모아서 visualize하는 방식이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/92eacb5c-3685-44a4-8db2-357243cc80cf" height="30%" width="30%"></p>

대표적으로는 t-SNE라는 방식으로 CNN의 시각으로 볼 때 유사한 것을 가까운 곳으로 위치시켜서 클러스터링 하는 방법이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/e6bc782e-30e2-4c72-8625-349f493c3094" height="60%" width="60%"></p>

네 번째 방법으로는 Occlusion experiments라는 방법으로 은닉을 통해 실험을 하는 것이다. 
위 사진을 자세히 보면 회색으로 가려진 부분이 있는데 이 부분을 0으로 된 행렬로 은폐시켜서 
이 은폐시키는 사각형을 sliding 시키면서 위치에 따라 classification 확률이 어떻게 변하는지 관찰한다. 

2열의 결과 사진을 보면 예상할 수 있듯이 강아지의 경우 얼굴 사진을 가리면 확률이 크게 감소하게 되고, 
자동차의 경우엔 바퀴부분을 가리는 경우 분류 능력이 떨어지는 것을 볼 수 있다.    

https://youtu.be/AgkfIQ4IGaM 실제 이 영상을 보면 우리가 따로 요청을 하지 않았음에도 네트워크가 학습을 진행하면서 어떤 뉴런은 옷의 주름, 어떤 뉴런은 text 이런식으로 알아서 각각의 역할을 한다는 것을 알 수 있다. 

영상에서도 언급이 되었다시피 Activation을 Visualize하는데는 아래 2가지 접근 방법이 있다.    

1. Deconvolution-based approach
2. Optimization-based approach

### Deconvolution-based approach
우선 Deconvolution-based approach가 무엇인지 알기 위해서 이미지가 input으로 들어왔을 때 특정 layer의 어느 한 뉴런의 
gradient를 어떻게 계산할지에 대한 질문에 답을 해야 한다. 일단 임의의 뉴런이 존재하는 곳 까지만 forward pass를 해주고, 
activation을 구한 다음 해당 layer에 있는 뉴런들에서 우리가 보고자 하는 임의의 뉴런을 제외한 나머지 뉴런들의 gradient를 
모두 0으로 만들어주고 해당 임의의 뉴런에 대해서만 gradient를 1.0으로 주고 여기에서 부터 역전파를 진행하면 된다. 
이렇게 하면 이미지에 대한 gradient를 시각화하여 볼 수 있게 된다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/fc609e09-b5f2-4bc2-953c-255b8c508f9e" height="50%" width="50%"></p>

하지만 이때 왼쪽 사진과 같이 애매한 시각화 결과가 나올 수 있는데, 이때는 그냥 역전파가 아니라 Guided backpropagation을 이용하면 된다. 
Guided backpropagation을 사용하게 되면 positive한 요소만 역전파 시에 반영하여 이전 왼쪽 이미지 처럼 negative한 요소와 
상쇄되어 애매한 결과가 나오지 않고 더 선명하게 나오게 된다.  
Guided backpropagation은 다른 것은 바뀌는 것이 없고 relu만 modified relu로 사용한 것이다.  

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/91c14885-0f4a-4d34-9d6a-e9e6a0909537" height="70%" width="70%"></p>

a를 보면 forward pass를 거치고 결과로 나온 feature map에서 관찰하고자 하는 뉴런이 숫자 '2'가 적힌 뉴런이라고 하면 
해당 뉴런의 gradient만 1로하고 나머지는 0으로 바꿔버린다.  
b의 relu의 경우를 보면 input에 대해 0보다 작은 부분은 모두 0으로 처리하고 역전파의 경우 앞서 0으로 바뀐 4군데 빼고 
나머지는 값 그대로 전달되는 것을 확인할 수 있다. 

Guided backpropagation의 경우에는 이전 forward pass에서 relu에 의해 0으로 처리된 부분 외에 
역전파 시에도 0보다 작은 값들이 전부 0으로 바뀌게 된다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/cba99fb8-6677-423b-ab9f-67b1c03fb6aa" height="50%" width="50%"></p>

Deconvolution-based의 또다른 방법으로 deconvnet이라는 것도 제시가 되었었는데, deconvnet은 relu의 영향을 받지 않고 
그냥 역전파 시에 0보다 작은 값들만 0으로 처리하게 된다. 물론 양수 값들은 그대로 전달이 된다. 이 방법 역시 잘 동작을 하게 된다. 

### Optimization-based approach
Optimization-based approach는 Optimization to Image로 이미지에 대해 최적화를 하는 것이다. 
이미지가 Optimization의 대상이 되는 파라미터가 되는 것이다. 
즉 일반적으로는 weight들이 파라미터가 되었었는데, 이와는 다르게 weight 파라미터들을 고정시켜두고 
이미지를 파라미터로 이용하게 되고 update도 weight가 아닌 이미지를 update하게 된다. 

그래서 특정 class의 score를 최대화 하는 이미지를 찾으려 하는데, 그 때 사용되는 식이 아래와 같다 

$$arg \ \underset{I}\max S_c(I) - \lambda||I|_2^2$$

$S_c$는 Softmax 이전 class c에 대한 score이고, 
뒤에 두 번째 term 같은 경우 L2 regularization과 같은 term이 들어가게 되는 것이다. 

# Reference
https://www.youtube.com/watch?v=j_BeROoelLo&list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&index=8  
