# Convolutional Neural Networks
## Filter
지금까지 우리가 다뤘던 Fully Connected Layer는 벡터를 펴서 내적 연산을 하는 방식이었다. 
CNN은 이미지를 분석하는데 있어서 패턴을 찾아내는데 매우 좋은 알고리즘이다. 
이렇게 알아낸 이미지 패턴을 통해 직접적으로 이미지를 학습하고 분석하는 것이 가능하다. 
CNN의 핵심은 기존 이미지 데이터의 structure을 보존하며 계산을 한다는 것이다. 

아래 하늘색 필터가 이미지 내를 슬라이딩 하면서 공간적인 내적을 하게 된다. 
모든 depth에 대해 내적이 진행되어야 하기 때문에, 필터의 depth는 input의 depth와 항상 같다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/4074bf2a-2918-472c-a78c-b1c2b62adfaa" height="50%" width="50%"></p>

output을 만드는 과정은 filter와 겹쳐놓고 내적하고, 슬라이딩하고 옆에서 계속 내적해서 output activation map의 해당 위치에 전달하는 방식이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/78cc7780-8783-4e1c-bbb1-9b813c25fb52" height="50%" width="50%"></p>

보통 convolution layer은 여러개의 필터를 사용한다. 이렇게 하면 필터마다 다른 특징을 추출할 수 있게 된다. 
한 레이어에서 아래와 같이 자신이 원하는 만큼 필터를 사용할 수 있다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/efe4dd14-fb65-47d1-8c77-b689f3b8e912" height="50%" width="50%"></p>

이를 반복하게 되는데, 이 사이사이에 activation, pooling 등이 들어간다. layer는 여러개의 필터를 가지고 있고, 각 필터마다 각각의 출력 map을 만든다. 
여러 레이어들을 거치면서 각 필터들이 계층적으로 학습이 가능해지는 것이다. 

## Kernel 
height와 width이 2 Dim을 sliding 해가면서 weighted sum을 수행한다고 하면 아래와 같이 2D convolution이 되는 것이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/ad6b5846-b15f-4993-b49c-3c7098e582b2" height="60%" width="60%"></p>

아래와 같이 데이터(10x10x3)를 convolution 한다고 하자. 만약 입력이 3D tensor가 입력된다 하더라고 커널이 1Dim 상에서만 sliding 하면 1D convolution이 되는 것이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/2606132a-6c77-4df7-88dc-ade02fd2ad48" height="60%" width="60%"></p>

엄밀히 말하면 앞서 말한 Filter와 Kernel은 차이가 있다. 
 kernel이라는 것은 sliding window 하는 영역에서의 크기이다. 여기에서는 4x4이라고 할 수 있다. filter라는 것은 실제로 kernel이 weighted sum 하는 영역의 크기이다. 여기에서는 4x4x3이라고 할 수 있다. 

4x4kernel에서 color 축으로 쌓인 모든 값들 즉 아래 그림을 토대로 4x4x3 cube모양을 eighted sum을 하여 스칼라 값을 산출해야한다. 즉, 이러한 weighted sum을 하기 위해서 4x4 kernel이 실제로는 4x4x3 이라는 weight를 가지고 있어야 된다. 엄밀히 말하면 kernel과 filter는 다른데 통상적으로 구분하지 않고 사용하게 된다.

특징을 추출하는 Kernel에는 여러가지 종류가 있다. 대표적인 몇가지를 살펴보자. 

### Gaussian Blur Kernel

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/2fadf7d3-01eb-41e1-bd2f-494f3e110484" height="250" width="250">　　　　　　　　 
<img src="https://github.com/em-1001/AI/assets/80628552/c00f4c8f-9d18-43cd-923c-74c7e5c24c01" height="250" width="250"></p>

$$
\begin{bmatrix}
1&2&1\\
2&4&2\\
1&2&1\\
\end{bmatrix}
\times \frac{1}{9}　　
Gaussian \ Blur \ Kernel
$$

### Sharpen Kernel 
<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/2fadf7d3-01eb-41e1-bd2f-494f3e110484" height="250" width="250">　　　　　　　　
<img src="https://github.com/em-1001/AI/assets/80628552/50656c5c-38d8-49de-a8d8-d3826edc2301" height="250" width="250"></p>

$$
\begin{bmatrix}
-1&-1&-1\\
-1&5&-1\\
-1&-1&-1\\
\end{bmatrix}　　
Sharpen \ Kernel
$$

### Vertical Edge, Horizontal Edge Kernel (Sobel x, Sobel y)
<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/e2bb9ad7-f1e6-46e7-8d07-92a7031fb46e" height="250" width="250">　　　　　　　　
<img src="https://github.com/em-1001/AI/assets/80628552/a71255b9-b386-4c2c-b651-f9ba6cd4d1fc" height="250" width="250"></p>

$$
\begin{bmatrix}
-1&0&1\\
-2&0&2\\
-1&0&1\\
\end{bmatrix}　　
Vertical \ Edge \ Kernel
$$

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/e2bb9ad7-f1e6-46e7-8d07-92a7031fb46e" height="250" width="250">　　　　　　　　
<img src="https://github.com/em-1001/AI/assets/80628552/2e01a7cb-e060-48eb-8d8d-73a188bc0641" height="250" width="250"></p>

$$
\begin{bmatrix}
1&2&1\\
0&0&0\\
-1&-2&-1\\
\end{bmatrix}　　
Horizontal \ Edge \ Kernel
$$


<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/ea1efac9-94aa-4dcc-95a7-069019b61635" height="250" width="250"></p>

$$Sobel \ X \ + \ Sobel \ Y$$

$$
\begin{bmatrix}
1&0&-1\\
0&0&0\\
-1&0&1\\
\end{bmatrix}　　　
\begin{bmatrix}
0&1&0\\
1&-4&1\\
0&1&0\\
\end{bmatrix}　　　
\begin{bmatrix}
-1&-1&-1\\
-1&8&-1\\
-1&-1&-1\\
\end{bmatrix}　　
Edge \ Detection \ Kernels
$$
