# Convolutional Neural Networks
지금까지 우리가 다뤘던 Fully Connected Layer는 벡터를 펴서 내적 연산을 하는 방식이었다. 
CNN은 이미지를 분석하는데 있어서 패턴을 찾아내는데 매우 좋은 알고리즘이다. 
이렇게 알아낸 이미지 패턴을 통해 직접적으로 이미지를 학습하고 분석하는 것이 가능하다. 
CNN의 핵심은 기존 이미지 데이터의 structure을 보존하며 계산을 한다는 것이다. 

## Filter
아래 하늘색 필터가 이미지 내를 슬라이딩 하면서 공간적인 내적을 하게 된다. 
모든 depth에 대해 내적이 진행되어야 하기 때문에, 필터의 depth는 input의 depth와 항상 같다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/4074bf2a-2918-472c-a78c-b1c2b62adfaa" height="50%" width="50%"></p>

output을 만드는 과정은 filter와 겹쳐놓고 내적하고, 슬라이딩하고 옆에서 계속 내적해서 output activation map의 해당 위치에 전달하는 방식이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/78cc7780-8783-4e1c-bbb1-9b813c25fb52" height="50%" width="50%"></p>

보통 convolution layer은 여러개의 필터를 사용한다. 이렇게 하면 필터마다 다른 특징을 추출할 수 있게 된다. 
한 레이어에서 아래와 같이 자신이 원하는 만큼 필터를 사용할 수 있다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/efe4dd14-fb65-47d1-8c77-b689f3b8e912" height="50%" width="50%"></p>

이를 반복하게 되는데, 이 사이사이에 activation, pooling 등이 들어간다. layer는 여러개의 필터를 가지고 있고, 각 필터마다 각각의 출력 map을 만든다. 
여러 레이어들을 거치면서 각 필터들이 계층적으로 학습이 가능해지는 것이다. 

## Kernel 
height와 width이 2 Dim을 sliding 해가면서 weighted sum을 수행한다고 하면 아래와 같이 2D convolution이 되는 것이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/ad6b5846-b15f-4993-b49c-3c7098e582b2" height="60%" width="60%"></p>

아래와 같이 데이터(10x10x3)를 convolution 한다고 하자. 만약 입력이 3D tensor가 입력된다 하더라고 커널이 1Dim 상에서만 sliding 하면 1D convolution이 되는 것이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/2606132a-6c77-4df7-88dc-ade02fd2ad48" height="60%" width="60%"></p>

엄밀히 말하면 앞서 말한 Filter와 Kernel은 차이가 있다. 
 kernel이라는 것은 sliding window 하는 영역에서의 크기이다. 여기에서는 4x4이라고 할 수 있다. filter라는 것은 실제로 kernel이 weighted sum 하는 영역의 크기이다. 여기에서는 4x4x3이라고 할 수 있다. 

4x4kernel에서 color 축으로 쌓인 모든 값들 즉 아래 그림을 토대로 4x4x3 cube모양을 eighted sum을 하여 스칼라 값을 산출해야한다. 즉, 이러한 weighted sum을 하기 위해서 4x4 kernel이 실제로는 4x4x3 이라는 weight를 가지고 있어야 된다. 엄밀히 말하면 kernel과 filter는 다른데 통상적으로 구분하지 않고 사용하게 된다.

특징을 추출하는 Kernel에는 여러가지 종류가 있다. 대표적인 몇가지를 살펴보자. 

### Gaussian Blur Kernel

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/2fadf7d3-01eb-41e1-bd2f-494f3e110484" height="250" width="250">　　　　　　　　 
<img src="https://github.com/em-1001/AI/assets/80628552/c00f4c8f-9d18-43cd-923c-74c7e5c24c01" height="250" width="250"></p>

$$
\begin{bmatrix}
1&2&1\\
2&4&2\\
1&2&1\\
\end{bmatrix}
\times \frac{1}{9}　　
Gaussian \ Blur \ Kernel
$$

### Sharpen Kernel 
<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/2fadf7d3-01eb-41e1-bd2f-494f3e110484" height="250" width="250">　　　　　　　　
<img src="https://github.com/em-1001/AI/assets/80628552/50656c5c-38d8-49de-a8d8-d3826edc2301" height="250" width="250"></p>

$$
\begin{bmatrix}
-1&-1&-1\\
-1&5&-1\\
-1&-1&-1\\
\end{bmatrix}　　
Sharpen \ Kernel
$$

### Vertical Edge, Horizontal Edge Kernel (Sobel x, Sobel y)
<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/e2bb9ad7-f1e6-46e7-8d07-92a7031fb46e" height="250" width="250">　　　　　　　　
<img src="https://github.com/em-1001/AI/assets/80628552/a71255b9-b386-4c2c-b651-f9ba6cd4d1fc" height="250" width="250"></p>

$$
\begin{bmatrix}
-1&0&1\\
-2&0&2\\
-1&0&1\\
\end{bmatrix}　　
Vertical \ Edge \ Kernel
$$

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/e2bb9ad7-f1e6-46e7-8d07-92a7031fb46e" height="250" width="250">　　　　　　　　
<img src="https://github.com/em-1001/AI/assets/80628552/2e01a7cb-e060-48eb-8d8d-73a188bc0641" height="250" width="250"></p>

$$
\begin{bmatrix}
1&2&1\\
0&0&0\\
-1&-2&-1\\
\end{bmatrix}　　
Horizontal \ Edge \ Kernel
$$


<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/ea1efac9-94aa-4dcc-95a7-069019b61635" height="250" width="250"></p>

$$Sobel \ X \ + \ Sobel \ Y$$

$$
\begin{bmatrix}
1&0&-1\\
0&0&0\\
-1&0&1\\
\end{bmatrix}　　　
\begin{bmatrix}
0&1&0\\
1&-4&1\\
0&1&0\\
\end{bmatrix}　　　
\begin{bmatrix}
-1&-1&-1\\
-1&8&-1\\
-1&-1&-1\\
\end{bmatrix}　　
Edge \ Detection \ Kernels
$$

결과적으로 아래 그림과 같이 여러개의 conv layer을 거치면서 단순한 구조에서 더 복잡한 구조로 찾아감을 볼 수 있다. 각 그리드는 하나의 뉴런(필터)이다. 마지막에는 FC layer을 통해 스코어를 계산하게 된다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/f2e7aa64-4502-4e3d-982d-45aa63154923" height="70%" width="70%"></p>

차원에 대해서도 살펴보자. 필터를 몇칸씩 움직일지를 stride로 정할 수 있다. 보통 input 사이즈와 슬라이딩 시 딱 맞아떨어지는 stride만을 이용한다. 다음과 같이 출력의 크기를 구할 수 있다. 

$$ Output \ Size \ : \ (N - F) / stride + 1$$

Input Dim : N     
Filter Size : F  

stride를 설정해 줌으로써 pooling과 같이 다운샘플링할 수 있고, 더 좋은 성능을 가져다주기도 한다. 
이는 activation map의 사이즈를 줄이는 것이고, 나중에 FC layer의 파라미터의 수가 줄어들게 되는 것이다. 

Convolution layer output size는 아래와 같이 구할 수 있다.   
Input Data Height: H  
Input Data Width: W  
Filter Height: 𝐹ℎ  
Filter width: 𝐹𝑤  
Strid Size: S  
Padded Size: P  

$$Output \ Height = OH = \frac{H + 2P - F_h}{S} + 1$$

$$Output \ Width = OW = \frac{H + 2P - F_w}{S} + 1$$

## Zero Padding 
Zero Padding은 코너에 있는 값들이 적게 연산되는 것을 막아주고, 레이어들을 거치면서 입력의 사이즈가 줄어드는 것을 막아준다. 
깊은 네트워크에서는 Activation map이 엄청나게 작아지게 되고, 이는 정보를 잃는 것이다. 
따라서 항상 원본 이미지를 표현하기에 충분한 차원을 사용해야 한다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/27c0ac74-c269-43ee-b974-ee57f3ec65f2" height="70%" width="70%"></p>

0 padding을 추가하면 모서리에 필요없는 특징을 추가하는 것이라 생각할 수도 있는데 zero-padding은 꽤 좋은 하나의 방법일 뿐이고,
mirror, extend 등도 있다. 

지금까지의 내용으로 예지를 풀어보자.   

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/3996512f-bf73-4044-b68b-e3087d5f99d3" height="60%" width="60%"></p>

필터당 5x5x3+1(bias)개의 파라미터 존재, 총 76*10=760개의 파라미터가 존재한다.

Output Volume Size는 (32+2*2-5)/1 + 1 = 32로 32x32x10이다. 

## Pooling Layer
CNN에 들어가는 다른 Layer로 Pooling Layer가 있다. 
Pooling Layer는 output data의 size를 줄여야 하거나, size를 줄이면서 data의 특정 부분을 강조하고 싶을 때 사용한다. 
또한 파라미터 수가 줄어들어 오버피팅을 방지해줄 수도 있다. 
Pooling Layer는 용도에 따라 여러 종류가 있다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/d56ded03-66ec-4515-b9ad-27a0c178681f" height="40%" width="40%"></p>

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/629cb3c0-8e98-4b62-becb-a80b1ae3b4f7" height="60%" width="60%"></p>

Pooling Layer output size는 다음과 같이 계산한다.    
Size(width) of output image : O  
Size(width) of input image : I   
Stride of the convolution operation : S   
Pooling Size : $P_s$  

$$O = \frac{I - P_s}{S} + 1$$

## ReLu(Rectified Linear Unit)

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/0a32ee18-9ad1-4cae-bf26-ad25775e33ea" height="50%" width="50%"></p>

ReLu(Rectified Linear Unit) 활성화 함수는 비선형성 함수로 기본 선형 특성을 나타내는 layer에 비선형성을 증가시켜 준다. 
ReLu 함수의 범위는 $R(z)=max(0, z)$ 양수이기 때문에 vanishing gradient 문제점을 극복하고 학습 속도와 성능을 향상시켜 CNN에서 주로 사용되는 활성화 함수이다. 

# Reference
https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=5  
https://oculus.tistory.com/10  
https://data-science-hi.tistory.com/128  


