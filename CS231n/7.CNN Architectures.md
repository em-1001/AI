# LeNet-5

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/e812544a-0904-4e8c-b46d-bed8bee9d361" height="80%" width="80%"></p>

그림에서 C는 Conv, S는 Subsampling(Pooling)이다. Conv, Pooling이 반복되다가 마지막에 FC를 거치고 output을 내놓는걸 확인할 수 있다. Filter는 Conv의 경우 5X5에 Stride는 1이고 Pooling의 경우는 2X2에 Stride는 2이다. 
이에 따라 처음에 32X32 input을 받고 Filter를 거쳐서 $(32-5)/1 + 1 = 28$로 28X28의 결과가 나오는 것을 확인할 수 있다. 
또한 Pooling 시에는 $(28 - 2) / 2 + 1 = 14$가 된다. 

`Conv - Pool - Conv - Pool - Conv - FC`


# AlexNet

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/47cb8fe9-dc42-4257-90f0-0f05100d3bdc" height="80%" width="80%"></p>

AlexNet는 input으로 227X227X3 size의 이미지를 받고 위 그림에서의 224는 오타이다. 그림 또한 원래 논문에서 사진이 조금 짤렸는데 위쪽 stream과 아래쪽 stream 이렇게 2개로 구성되어 있다. 
이렇게 2개의 stream으로 나누어서 설계한 이유는 당시 GPU의 성능이 좋지 못했기 때문에 2개의 GPU를 활용해 학습하였다. 현재는 하나로 GPU로 연산이 가능하다. 

AlexNet의 First layer를 보면 96개의 11X11 크기의 4 stride Filter를 거치게 된다. 따라서 First layer를 거친 후의 output size는 $(227 - 11)/4 + 1 = 55$가 되어 55X55X96이 된다. 
또한 전체 파라미터의 수는 input 의 depth가 3이었고, 11X11 Filter가 96개 있었으므로 $(11*11*3)*96 = 35k$가 된다. 

다음으로 Pooling layer의 경우 3X3에 stride는 2이다. 따라서 Pooling을 거치게 되면 마찬가지로 $(55 - 3)/2 + 1 =27$이 되어 27X27X96이 된다. 이때 Pooling layer에서 depth는 변하지 않는다.
또한 Pooling layer에서는 파라미터가 없으므로 0이다. 파라미터는 Conv에서만 존재한다.  

최종적으로 마지막까지 계산하한 내용과 AlexNet에 대해 정리한 내용은 아래와 같다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/67bf4ab2-1e56-4f85-b80b-fc39ed3745ea" height="70%" width="70%"></p>

참고로 Normalization layer는 현재 효용이 없다고 판단되어 사용되지 않는다. 과정을 보면 layer를 거칠수록 size는 점점 작아지는데 반해 filter의 수는 늘어나는 것을 볼 수가 있고, 
마지막 FC7 layer는 일반적으로 통칭되는 용어이기도 한데 FC7 layer는 classifier 직전의 layer를 보통 FC7 layer라고 한다. 


# ZFNet

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/b90290b4-b39b-420b-b7d5-dd28b39d6857" height="80%" width="80%"></p>

ZFNet은 기본적으로 AlexNet와 거의 유사한데 차이가 있다면 AlexNet에서는 Conv1 layer에서 11X11 stride 4의 Filter를 사용했는데 이 Filter가 너무 크다고 판단되어서 7X7 stride 2로 변경되었다. 
또한 Conv3, 4, 5에서는 Filter의 수를 각각 384, 384, 256에서 512, 1024, 512로 늘려주었다. 결국 Filter의 크기는 작게하고 수는 늘려준 것이다. 


# VGGNet

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/1501685a-2d12-4eef-aa15-fe1628070431" height="50%" width="50%"></p>

기존의 AlexNet과 같은데서는 Conv와 MAX Pooling layer에서의 Filter를 계속 변경을 해주었는데, VGGNet에서는 오직 Conv layer에서는 3X3 stride 1 pad 1이고, Pooling layer에서는 2X2 stride 2만을 모든 레이어에 적용하였다. 
따라서 위 사진을 보면 몇개의 weight layer를 가지는 모델이 최적일지를 탐구한 것이다. 결과적으로는 D모델이 가장 최적이 모델이라는 결론이 나왔다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/3e488e8f-661d-4a28-baee-54b73b6dc400" height="70%" width="70%"></p>

최종적으로 D모델을 기준으로 분석하면 위 사진과 같다. image사이즈는 224, 112, 56... 으로 계속 줄어드는 것을 볼 수 있고, 반면 Filter의 수는 64, 128, 256, 512로 계속 늘어남을 알 수 있다.  
가운데 사용된 메모리를 보면 전체 합산하면 


# Reference 
https://www.youtube.com/watch?v=rdTCxAM1I0I&list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&index=6   
