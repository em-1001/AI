# LeNet-5

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/e812544a-0904-4e8c-b46d-bed8bee9d361" height="80%" width="80%"></p>

그림에서 C는 Conv, S는 Subsampling(Pooling)이다. Conv, Pooling이 반복되다가 마지막에 FC를 거치고 output을 내놓는걸 확인할 수 있다. Filter는 Conv의 경우 5X5에 Stride는 1이고 Pooling의 경우는 2X2에 Stride는 2이다. 
이에 따라 처음에 32X32 input을 받고 Filter를 거쳐서 $(32-5)/1 + 1 = 28$로 28X28의 결과가 나오는 것을 확인할 수 있다. 
또한 Pooling 시에는 $(28 - 2) / 2 + 1 = 14$가 된다. 

`Conv - Pool - Conv - Pool - Conv - FC`


# AlexNet

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/47cb8fe9-dc42-4257-90f0-0f05100d3bdc" height="80%" width="80%"></p>

AlexNet는 input으로 227X227X3 size의 이미지를 받고 위 그림에서의 224는 오타이다. 그림 또한 원래 논문에서 사진이 조금 짤렸는데 위쪽 stream과 아래쪽 stream 이렇게 2개로 구성되어 있다. 
이렇게 2개의 stream으로 나누어서 설계한 이유는 당시 GPU의 성능이 좋지 못했기 때문에 2개의 GPU를 활용해 학습하였다. 현재는 하나로 GPU로 연산이 가능하다. 

AlexNet의 First layer를 보면 96개의 11X11 크기의 4 stride Filter를 거치게 된다. 따라서 First layer를 거친 후의 output size는 $(227 - 11)/4 + 1 = 55$가 되어 55X55X96이 된다. 
또한 전체 파라미터의 수는 input 의 depth가 3이었고, 11X11 Filter가 96개 있었으므로 $(11*11*3)*96 = 35k$가 된다. 

다음으로 Pooling layer의 경우 3X3에 stride는 2이다. 따라서 Pooling을 거치게 되면 마찬가지로 $(55 - 3)/2 + 1 =27$이 되어 27X27X96이 된다. 이때 Pooling layer에서 depth는 변하지 않는다.
또한 Pooling layer에서는 파라미터가 없으므로 0이다. 파라미터는 Conv에서만 존재한다.  

최종적으로 마지막까지 계산하한 내용과 AlexNet에 대해 정리한 내용은 아래와 같다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/67bf4ab2-1e56-4f85-b80b-fc39ed3745ea" height="70%" width="70%"></p>

참고로 Normalization layer는 현재 효용이 없다고 판단되어 사용되지 않는다. 과정을 보면 layer를 거칠수록 size는 점점 작아지는데 반해 filter의 수는 늘어나는 것을 볼 수가 있고, 
마지막 FC7 layer는 일반적으로 통칭되는 용어이기도 한데 FC7 layer는 classifier 직전의 layer를 보통 FC7 layer라고 한다. 


# ZFNet

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/b90290b4-b39b-420b-b7d5-dd28b39d6857" height="80%" width="80%"></p>

ZFNet은 기본적으로 AlexNet와 거의 유사한데 차이가 있다면 AlexNet에서는 Conv1 layer에서 11X11 stride 4의 Filter를 사용했는데 이 Filter가 너무 크다고 판단되어서 7X7 stride 2로 변경되었다. 
또한 Conv3, 4, 5에서는 Filter의 수를 각각 384, 384, 256에서 512, 1024, 512로 늘려주었다. 결국 Filter의 크기는 작게하고 수는 늘려준 것이다. 


# VGGNet

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/1501685a-2d12-4eef-aa15-fe1628070431" height="50%" width="50%"></p>

기존의 AlexNet과 같은데서는 Conv와 MAX Pooling layer에서의 Filter를 계속 변경을 해주었는데, VGGNet에서는 오직 Conv layer에서는 3X3 stride 1 pad 1이고, Pooling layer에서는 2X2 stride 2만을 모든 레이어에 적용하였다. 
따라서 위 사진을 보면 몇개의 weight layer를 가지는 모델이 최적일지를 탐구한 것이다. 결과적으로는 D모델이 가장 최적이 모델이라는 결론이 나왔다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/3e488e8f-661d-4a28-baee-54b73b6dc400" height="70%" width="70%"></p>

최종적으로 D모델을 기준으로 분석하면 위 사진과 같다. image사이즈는 224, 112, 56... 으로 계속 줄어드는 것을 볼 수 있고, 반면 Filter의 수는 64, 128, 256, 512로 계속 늘어남을 알 수 있다.  
가운데 사용된 메모리를 보면 전체 합산하면 24M이 되고 float point 4바이트를 기준으로 하면 24M * 4 ~= 93MB / image가 된다.
이는 하나의 이미지 기준이며 forward 기분이고 backword까지 고려하면 이미지 한장을 처리하는데 약 200메가의 메모리를 사용하게된다.

메모리 사용 변화를 좀 더 자세히 보면 앞단 layer에서 주로 메모리를 사용하는 것을 볼 수 있고, 파라미터의 경우 뒤로 갈수록 파라미터의 수가 점점 늘어나면서 뒤쪽 FC에서 무려 1억개의 파라미터가 사용되는 것을 볼 수 있다. 이 때문에 FC layer를 사용하는 것이 효율적이지 않다는 판단이 나왔고, 최근에는 FC 대신 average Pooling사용에 대한 연구가 많이 되었다. 그래서 첫 FC layer를 보면 7*7*512*4096이 있을 때, 각 7X7을 average pooling을 해줘서 512개의 수를 가지는 단일 column으로 변환해준다. 실제 동작에서는 FC 만큼의 성능을 보이면서 파라미터 수는 크게 줄여줘서 매우 효율적으로 잘 동작하게 된다. 이 개념은 이후의 GoogLeNet에서도 사용된다. 


# GoogLeNet

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/3785ef24-6d28-4fe6-8294-c8d8a4eb7df5" height="100%" width="100%"></p>

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/c5bb9fb2-8ceb-4809-be66-15ff1154350d" height="50%" width="50%"></p>

GoogLeNet은 매우 복잡하다. 바로 위 사진을 Inception Module이라 하는데, GoogLeNet은 이런 Inception Module이 연속적으로 이어진 형태를 가지고 있다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/730f970c-9815-46c8-99fd-4ed8a0acb648" height="80%" width="80%"></p>

GoogLeNet의 구성을 잘 보면 앞서 언급한 avg pooling을 사용하는 것을 알 수 있다. avg pool을 보면 이전 layer에서 7x7x1024였던것이 avg pool을 거치고 1x1x1024가 됨을 알 수 있다. 
이렇게 단일 column으로 만들어 버림으로써 파라미터 수가 크게 줄었고 다 합쳐도 약 500만 정도밖에 되지 않는다. 

파라미터 수를 비교해보면 AlexNet : 60M, VGG : 138M, GoogLeNet : 5M 으로 크게 줄었다. 


# ResNet
ResNet은 이전 아키텍쳐들에 비해 ImageNet Classification 뿐만 아니라 Detection, Localization 그리고 COCO Detection, COCO Segmentation의 분야까지 모두 1등을 하였다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/ccc36021-50f9-4e2f-893d-9ad5f2d6db8b" height="60%" width="60%"></p>

이전 아키텍쳐 부터 layer의 수를 보면 매우 얕은 shallow부터 시작해서 천천히 증가하다가 ResNet에서 152개로 크게 증가함을 볼 수 있다. 
반면 Error rate는 점점 감소하게 된다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/1c52a459-8fcb-472a-8e1f-3d5672188378" height="70%" width="70%"></p>

기본적으로는 layer가 많아질 수록 더 좋은 성능을 가져와야 한다. 하지만 문제들도 존재한다. 
ResNet이 말하는 바는 Alex나 VGG와 같은 것들은 layer가 많아짐에 따라 error가 오히려 더 커지므로 현재까지의 아키텍쳐들은 
최적화에 실패했다는 것이다. 
반면 ResNet같은 경우 layer가 많아질수록 정상적으로 error가 줄어들고 있다. 따라서 점점 많은 layer를 사용하기 위해서는 ResNet의 layer를 따라야 한다고 한다. 

ResNet의 놀라운 점은 layer의 수가 이전 아키텍쳐들에 비해 매우 급격하게 증가했다는 것이다. 
이에 따라 8개의 GPU로 2~3주 동안 오래 학습시켜야 하는대신 test 시에는 매우 빠른 속도를 보인다. 

### Residual block

H(x)를 기존의 네트워크라고 할 때, H(x)를 복잡한 함수에 근사시키는 것 보다 F(x) := H(x) - x일 때, H(x) = F(x) + x이고, F(x) + x를 근사시키는 것이 더 쉬울 것이라는 아이디어에서 출발하였다.
원래 Output에서 자기자신을 빼는 것이 F(x)의 정의이므로, 'Residual learning'이라는 이름을 갖게 된다. 
x가 F(x)를 통과하고 나서 다시 x를 더해주기 때문에 이를 Skip Connection이라고 부른다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/bc359a22-3e71-42d9-80fb-690311db6f5f" height="50%" width="50%"></p>

#### Skip Connections


# Reference 
https://www.youtube.com/watch?v=rdTCxAM1I0I&list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&index=6   
https://linkinpark213.com/2018/04/22/resnet/    
https://wikidocs.net/137252
