# RNN

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/640b40bb-b39a-4cce-87b3-1ebf0b835b93" height="80%" width="80%"></p>

지금까지 봐온 일반적인 one-to-one 네트워크와는 달리 RNN은 output이나 input이 여러개로 sequence를 이루는 경우가 있다.   
one-to-many는 image captioning으로 예를 들 수 있다. 이는 이미지 하나를 입력 받고 이미지에 대한 설명을 출력으로 내는 것이다.   
many-to-one의 경우는 Sentiment Classification으로 예를 들 수 있다. 이는 감정을 분류해 내는 것으로 단어들로 구성된 시퀀스(티위터 메시지, 편지 등)을 입력받고 이 글에서 나오는 감정이 positive냐 negative냐 등을 분류한다.   
many-to-many는 Machine Translation으로 예를 들 수 있다. 예를 들어 영어 단어로 구성된 문장을 입력받으면 이를 한국어로 번역해주는 것이다.   
many-to-many의 또 다른 예는 Video classification on frame level이라는 것으로 모든 하나하나의 프레임들을 classify하여 예측이 현재 시점의 프레임에서 국한된 것이 아니라 현재까지 지나온 모든 비디오의 프레임을 기반으로 예측을 한다.        


<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/a2d6be5c-68be-4105-9a05-2c733d005323" height="25%" width="25%"></p>

위 이미지는 fixed input을 Sequential하게 처리한 경우이다. 이는 CNN으로 이미지를 받아서 집 번지수를 classify한 것이 아니라 RNN을 이용해서 이미지 하나를 Sequential하게 훑어나간다. 반대로 fixed size의 output을 Sequential하게 처리해서 출력할 수도 있다. 번지 수로 예를들면 번지 수를 한번에 출력하는게 아니라 Sequential하게 사람이 글로 써내려가듯이 출력해준다. 이러한 예시들은 one to one의 경우에도 CNN이 아니라 RNN을 통해 분석할 수 있음을 보여준다. 

## RNN mechanism

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/78f20972-0432-479d-86ce-f79e7777d974" height="80%" width="80%"></p>

RNN은 매 time step마다 input vector가 RNN으로 입력이 된다. RNN은 내부적으로 state를 가지게 되고 이 state를 함수로 변형해 줄 수 있다. 이 함수는 매 time step마다 input을 받는 것에 대한 함수이다. 이러한 RNN도 weight로 구성이 되며 weight들을 튜닝하면서 RNN을 학습시키게 된다. 이렇게 하므로써 우리가 얻는 값은 특정 time step에서의 값에 대한 예측값인 것이다. 그래서 위 사진과 같이 입력되는 vector x에 대해서 왼쪽과 같은 recurrence function을 적용할 수 있게 된다. 결론적으로 이 RNN이 우리가 원하는 특정 behavior를 가질 수 있도록 weight값들을 학습시켜 나가는 것이다. 

주의할 점은 매 time step마다 동일한 함수와 동일한 파라미터 set이 사용돼야 한다는 것이다. 
이렇게 해야 input sequence size와 output sequence size에 무관하게 적용이 가능하게 된다. 
다시 말하면 input/output sequence size가 아무리 커도 상관이 없다는 것이다. 

### Vanilla RNN

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/6717b3de-e5e3-4193-bd4f-c41d45c598b6" height="80%" width="80%"></p>

recurrence function을 적용한 가장 간단한 사례가 Vanilla RNN이다. 
Vanilla RNN에서는 state가 단일의 hidden vector h로만 구성이 된다. 
Vanilla RNN에서의 state update는 두 번째 식과 같이 된다고 볼 수 있다. 
$x_t$이 경우는 weight값이 $x$에서 hidden layer로 가는 $W_{xh}$에 영향을 받고, 직전의 상태 $h_{t-1}$의 경우 직전의 hidden layer와 현재의 hidden layer의 영향을 받게 된다. 
즉 현재의 state $h_t$는 과거의 상태와 새로운 input으로 바뀌는 것을 알 수 있다. 

### Character-level language model example 
Character들의 sequence를 feeding해주고 매 순간 RNN에게 다음 step에 올 Character를 예측하도록 하는 예시이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/869dfc20-fa02-4ecd-b4c9-fd9af5f338e3" height="80%" width="80%"></p>

RNN에 feeding 해주는 input은 one-hot encodeing 방식으로 넣어주고 우선 "hell"순으로 순차적으로 feeding해 준다. hidden layer는 임의의 3개의 뉴런으로 구성된다 가정을 했다. 이전의 hidden layer는 다음의 hidden layer에 영향을 주고 이를 $W_{hh}$라고 표현한다. 그리고 input layer에서 hidden layer로 영향을 주는 것을 $W_{xh}$로 표현하였다. 

output layer로 나오는 결과를 보면 우리가 원하는 결과는 "ello"가 나와야 하는데 RNN이 정답값으로 예측한 값을 보면 첫 번째의 경우 'o'를 4.1로 가장 높게 잘못예측하였다. 그래서 이러한 값들을 정답값과 비교를 하여 loss를 구하고 다시 input layer 방향으로 역전파를 한다. 이런식으로 가중치를 조정하여 학습을 하게 되고 각각의 time step에는 softmax classifier로 loss를 구하게 된다. 

그리고 또 살펴볼 점은 앞서 말했듯이 매 time step마다 동일한 함수와 동일한 파라미터 set이 사용된다고 했으므로 사진에서 보이는 각각의 $W_{xh}, W_{hh}, W_{hy}$들은 동일한 것이라 볼 수 있다. 


27분 55초 

# Reference 
https://www.youtube.com/watch?v=2ngo9-YCxzY&t=213s  
