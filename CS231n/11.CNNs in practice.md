# Data Augmentation 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/805152c9-90be-4060-97f0-9745c4be4530" height="80%" width="80%"></p>

일반적인 CNN은 이미지와 label을 CNN에 feed해주고 loss를 구해서 최적화 하는 방법을 사용한다. Data Augmentation은 여기에 위 사진과 같이 input image를 변형하는 과정이 하나 추가된다. 

그래서 Data Augmentation은 label에는 변화가 없지만 픽셀에는 변화를 주고 이런 변경된 데이터로 학습을 하게 된다. 
간단한 예시 몇 가지로 아래와 같은 것들이 있다. 

## 1. Horizontal flips

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/6a340fb5-5188-4100-b8e7-fd62123be2d0" height="50%" width="50%"></p>

## 2. Random Crops/Scales

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/294755a9-f59e-4b8c-841b-8a49d440b0ac" height="20%" width="20%"></p>

Random Crops/Scales은 이미지를 랜덤하게 자르거나 scale을 다양하게 해서 학습시키는 것이다.

**ResNet**  
1. Pick random L in range [256, 480]
2. Resize training image, short side = L
3. Sample random 224 X 224 path

예를 들어 ResNet에서는 이미지를 [256, 480] 사이의 L을 랜덤하게 선택해주고 training image를 resize해준다. 여기서 짧은 부분이 L이 되도록 하고 이후 랜덤하게 224 X 224 크기를 갖는 patch를 샘플링하여 추출한다. 

이러한 Augmentation을 이용하면 training 시에 이미지 전체가 아니라 crop(부분 부분)에 대한 학습이 이루어지기 때문에 test 시에도 이미지 전체가 아니라 정해진 수의 crop을 이용해서 test를 진행하게 된다. 

**Test Example**  
1. 테스트할 이미지를 5개의 크기로 resize해준다. (224, 256, 384, 480, 640)
2. 각각의 사이즈에 대해 224 X 224의 크기를 갖는 10개의 crop을 만들어 준다. (코너 부분의 crop 4개 + 중심 부분의 crop 1개 = 5개 -> 이를 Horizontal flips까지 해줘서 총 10개. 각각의 size에 대해 10개씩 이므로 총 50개.)
3. 그리고 이 50개에 대해 평균을 구해준다. 


## 3. Color jitter

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/cc30b487-1e55-4065-a642-038c14c01ce5" height="80%" width="80%"></p>


Color jitter의 가장 간단한 방법은 contrast를 jittering 해주는 것이고 이보다는 복잡하지만 많이 사용되는 방법은 이미지 각각의 RGB 채널에 대해 
PCA(주성분 분석)을 해준다. 주성분 분석을 해주는 이유는 이미지의 주성분을 뽑아냄으로써 이미지의 핵심을 잃지 않으면서 이미지의 갯수를 늘려줄 수 있기 때문이다.
주성분 분석을 해준면 각각의 채널에 대해서 principal component direction을 얻게 된다. 이는 컬러가 변화해나가는 방향성을 파악하는 것이고 이러한 principal component direction을 따라 color의 offset을 샘플링을 해주고
이 offset을 이미지 모든 픽셀에 더해준다. 

위와 같은 방법 외에도 translation, rotation, stretching, lens ditortions(랜즈 왜곡 효과) 등 다양한 방법이 존재한다. 


<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/bc663151-21a8-4775-96d4-1056da8bd810" height="80%" width="80%"></p>

그래서 이러한 Augmentation을 크게 보면 training과정은 랜덤한 노이즈를 더해주는 과정이 되고 test과정은 이러한 노이즈를 평균화 하는 과정이라고 생각할 수 있다. 
이렇게 보면 큰 의미로 dropout이나 drop connect들도 Data Augmentation의 일부라고 생각할 수 있다. 
마찬가지 맥락으로 batch normalization, model ensembles 등도 이와 유사한 효과를 가지고 있다. 

정리하면 Data Augmentation은 구현이 매우 간단하기 때문에 사용하면 좋고, 특히 data set의 크기가 작을 때 유용할 것이다.  


# Transfer Learning 
CNN으로 Transfer Learning하는 과정을 살펴보면 우선 모델을 imageNet에 training시킨다. imageNet에 training시킨다는 것은 우리가 직접 처음부터 학습시킬 수도 있고, 미리 학습된 모델(pre-trained model)을 가져올 수도 있다. 
이때 만약 우리의 dataset이 너무 작은 경우에는 FC-1000과 Softmax만을 남겨놓고 나머지 layer에 대해 다 Freezing을 해준다. 즉 Freezing 해준 layer의 파라미터들은 변하지 않게 되고 이렇게 Freezing 해준 부분을 feature extractor처럼 생각할 수 있다. 




# Reference 
https://www.youtube.com/watch?v=8kzgwfNSDfk&list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&index=10&t=222s
