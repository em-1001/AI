# Data Augmentation 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/805152c9-90be-4060-97f0-9745c4be4530" height="80%" width="80%"></p>

일반적인 CNN은 이미지와 label을 CNN에 feed해주고 loss를 구해서 최적화 하는 방법을 사용한다. Data Augmentation은 여기에 위 사진과 같이 input image를 변형하는 과정이 하나 추가된다. 

그래서 Data Augmentation은 label에는 변화가 없지만 픽셀에는 변화를 주고 이런 변경된 데이터로 학습을 하게 된다. 
간단한 예시 몇 가지로 아래와 같은 것들이 있다. 

## 1. Horizontal flips

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/6a340fb5-5188-4100-b8e7-fd62123be2d0" height="50%" width="50%"></p>

## 2. Random Crops/Scales

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/294755a9-f59e-4b8c-841b-8a49d440b0ac" height="20%" width="20%"></p>

Random Crops/Scales은 이미지를 랜덤하게 자르거나 scale을 다양하게 해서 학습시키는 것이다.

**ResNet**  
1. Pick random L in range [256, 480]
2. Resize training image, short side = L
3. Sample random 224 X 224 path

예를 들어 ResNet에서는 이미지를 [256, 480] 사이의 L을 랜덤하게 선택해주고 training image를 resize해준다. 여기서 짧은 부분이 L이 되도록 하고 이후 랜덤하게 224 X 224 크기를 갖는 patch를 샘플링하여 추출한다. 

이러한 Augmentation을 이용하면 training 시에 이미지 전체가 아니라 crop(부분 부분)에 대한 학습이 이루어지기 때문에 test 시에도 이미지 전체가 아니라 정해진 수의 crop을 이용해서 test를 진행하게 된다. 

**Test Example**  
1. 테스트할 이미지를 5개의 크기로 resize해준다. (224, 256, 384, 480, 640)
2. 각각의 사이즈에 대해 224 X 224의 크기를 갖는 10개의 crop을 만들어 준다. (코너 부분의 crop 4개 + 중심 부분의 crop 1개 = 5개 -> 이를 Horizontal flips까지 해줘서 총 10개. 각각의 size에 대해 10개씩 이므로 총 50개.)
3. 그리고 이 50개에 대해 평균을 구해준다. 


## 3. Color jitter

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/cc30b487-1e55-4065-a642-038c14c01ce5" height="80%" width="80%"></p>


Color jitter의 가장 간단한 방법은 contrast를 jittering 해주는 것이고 이보다는 복잡하지만 많이 사용되는 방법은 이미지 각각의 RGB 채널에 대해 
PCA(주성분 분석)을 해준다. 주성분 분석을 해주는 이유는 이미지의 주성분을 뽑아냄으로써 이미지의 핵심을 잃지 않으면서 이미지의 갯수를 늘려줄 수 있기 때문이다.
주성분 분석을 해준면 각각의 채널에 대해서 principal component direction을 얻게 된다. 이는 컬러가 변화해나가는 방향성을 파악하는 것이고 이러한 principal component direction을 따라 color의 offset을 샘플링을 해주고
이 offset을 이미지 모든 픽셀에 더해준다. 

위와 같은 방법 외에도 translation, rotation, stretching, lens ditortions(랜즈 왜곡 효과) 등 다양한 방법이 존재한다. 


<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/bc663151-21a8-4775-96d4-1056da8bd810" height="80%" width="80%"></p>

그래서 이러한 Augmentation을 크게 보면 training과정은 랜덤한 노이즈를 더해주는 과정이 되고 test과정은 이러한 노이즈를 평균화 하는 과정이라고 생각할 수 있다. 
이렇게 보면 큰 의미로 dropout이나 drop connect들도 Data Augmentation의 일부라고 생각할 수 있다. 
마찬가지 맥락으로 batch normalization, model ensembles 등도 이와 유사한 효과를 가지고 있다. 

정리하면 Data Augmentation은 구현이 매우 간단하기 때문에 사용하면 좋고, 특히 data set의 크기가 작을 때 유용할 것이다.  


# Transfer Learning 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/84039ac8-8c18-4dc0-b323-48e06ece0df1" height="80%" width="80%"></p>

CNN으로 Transfer Learning하는 과정을 살펴보면 우선 모델을 imageNet에 training시킨다. imageNet에 training시킨다는 것은 우리가 직접 처음부터 학습시킬 수도 있고, 미리 학습된 모델(pre-trained model)을 가져올 수도 있다.
dataset이 충분한 경우는 직접 학습시켜도 된다. 

이때 만약 우리의 dataset이 2번째 경우 처럼 너무 작은 경우에는 FC-1000과 Softmax만을 남겨놓고 나머지 layer에 대해 다 Freezing을 해준다. 즉 Freezing 해준 layer의 파라미터들은 변하지 않게 되고 이렇게 Freezing 해준 부분을 feature extractor처럼 생각할 수 있다. 그래서 우리의 dataset은 FC-1000, Softmax 이 부분에 대해서만 학습을 시키게 된다.  

만약 3번째 경우처럼 dataset이 너무 많지도 않고 너무 적지도 않은 경우에는 finetuning을 해주게 된다. 
사진에서 보이는 것처럼 가지고 있는 data의 양에 따라 Freeze하는 영역을 조율하며 학습을 시키게 된다. 
finetuning에서의 한 가지 팁이 있는데 finetuning하는 layer의 top layer(빨간색 박스의 연두색 정도의 부분)는 learning rate을 원래의 rate의 1/10정도를 사용하고 그 위(빨간색 박스의 주황색 정도의 부분)는 1/100, 그리고 그보다 위는 Freeze 부분이기 때문에 rate가 0 이렇게 설정한다고 한다.   

만약 Transfer Learning을 할 때 pre-trained된 모델이 학습한 class와 유사한 class들을 분류해야 한다면 2 번의 경우 처럼 끝 부분만 학습시켜도 성능이 좋고 만약 전혀 관련이 없는 데이터를 분류해야 한다면 Freeze하는 부분을 줄이고 학습시키는 layer를 늘려야 한다고 한다. 
그런데 의문점은 이렇게 학습시키는 layer를 늘리면서 전이학습을 진행한게 아에 처음부터 직접 학습시키는 것 보다 더 성능이 좋다고 하는데, 그 이유는 앞 layer의 filter를 보면 edge, color 등의 low level feature를 인지하고 뒷 layer로 갈 수록 점점 상위 레벨의 추상적인 것들을 인식하기 때문에 low level feature를 미리 학습시켜 놓는다는 것은 그 어떤 이미지를 분석하더라도 도움이 된다는 것이다. 그렇기 때문에 전이 학습이 더 좋은 성능을 낼 수 있는 것이다. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/6d6dfe89-1055-4375-8b3f-37c8d4cd1e1c" height="80%" width="80%"></p>

그래서 가지고 있는 data의 수와 pre-trained된 모델이 학습한 데이터와 자기가 분류하고 싶은 데이터 set과의 유사성에 따른 관계는 위 표로 정리할 수 있다. 

결론적으로 CNN에서의 Transfer learning은 거의 항상 사용된다고 보면 되고 object detection과 같은 Faster R-CNN에서도 CNN에서는 전이 학습을 사용을 하고 Image Captioning의 경우도 CNN부분은 물론 RNN부분에서도 word vector에 대한 전이 학습을 사용한다고 한다. (word2vec pre-training)

이러한 pre-trained model은 아래 사이트에서 찾아볼 수 있다.   
https://github.com/BVLC/caffe/blob/master/docs/model_zoo.md


# All About Convolutions
## Part1 : How to Stack them 
이제는 Convolutions에 대해 좀 더 자세히 살펴볼 것인데, 첫 파트는 어떻게 stacking을 할 것인가에 대해 알아볼 것이다. 

16분 4초 



# Reference 
https://www.youtube.com/watch?v=8kzgwfNSDfk&list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&index=10&t=222s
