# Background
## Adversarial Training
Adversarial Trainingì€ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ë¡œ ëª¨ë¸ì„ adversarial exampleì„ ì´ìš©í•´ í•™ìŠµì‹œí‚´ìœ¼ë¡œì„œ ëª¨ë¸ì´ ë”ìš± robustí•´ì§€ë„ë¡ í•˜ëŠ” ê²ƒì´ë‹¤. ì´ Adversarial Trainingì„ ì‚¬ìš©í•˜ëŠ” ì˜ˆì‹œë¡œ PGD learningì´ ìˆë‹¤.  
PGD Attackìœ¼ë¡œ ë§Œë“¤ì–´ì§„ adversarial exampleì— ëŒ€í•´ ë‹¤ì‹œ ì›ë³¸ classë¡œ ë¶„ë¥˜í•˜ë„ë¡ í•™ìŠµì‹œí‚¤ë©´ ì‹¤ì œ ê³µê²©ì´ ë“¤ì–´ì™”ì„ ë•Œ robustí•˜ê²Œ ë™ì‘í•œë‹¤ëŠ” ê²ƒì´ë‹¤. 

Adversarial Trainingì˜ ì¼ë°˜ì ì¸ Objective functionì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 

$$\underset{\theta}\min p(\theta), \ where \ p(\theta) = E_{(x, y) \sim D} [\underset{\delta \in S}\max L(\theta, x + \delta, y)]$$

$\underset{\delta \in S}\max L(\theta, x + \delta, y)$ ì´ ë¶€ë¶„ì€ PGDë¥¼ í†µí•´ ê³„ì‚°ì´ ë˜ëŠ”ë° adversarial example $x + \delta$ëŠ” $\delta \in S$ boundaryì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ì„œ ê¸°ì¡´ ëª¨ë¸ $\theta$ì— ëŒ€í•´ì„œ ìµœëŒ€í•œ Lossë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸ê°€ ëœë‹¤. ì´ë ‡ê²Œ Lossë¥¼ ìµœëŒ€í™” í•˜ëŠ” adversarial exampleì— ëŒ€í•´ì„œ ë‹¤ì‹œ Lossë¥¼ ìµœì†Œí™” ì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ Adversarial Trainingì„ í•˜ëŠ” ê²ƒì´ë‹¤. ì¦‰ adversarial exampleì„ ë§Œë“¤ê³  ì´ adversarial exampleì— ëŒ€í•´ì„œ ë‹¤ì‹œ ì›ë˜ì˜ classë¡œ ë¶„ë¥˜í•˜ë„ë¡ Lossë¥¼ ë‚®ì¶”ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ê²ƒì´ë‹¤.     
<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/2c173e6d-0405-4811-b01c-82e3ceb98512" height="70%" width="70%"></p>

ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ë©´ ê²°ê³¼ì ìœ¼ë¡œ ìœ„ ë¹¨ê°„ìƒ‰ ì„ ê³¼ ê°™ì€ decision boundaryë¥¼ ì–»ê²Œ ë˜ëŠ” ê²ƒì´ë‹¤. 


# Benchmarking Neural Network Robustness to Common Corruptions and Perturbations
ê¼­ adversarial exampleì„ í†µí•œ ê³µê²©ì´ ì•„ë‹ˆë”ë¼ë„ ì¸ê³µì§€ëŠ¥ì„ í™œìš©í•˜ë‹¤ë³´ë©´ ë°ì´í„° ì†ìƒê³¼ Perturbationì— ëŒ€í•´ ë‹¤ë¤„ì•¼í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤. ì´ì œë¶€í„° ë³¸ê²©ì ìœ¼ë¡œ ë³´ë‹¤ ì¼ë°˜ì ì¸ ë°ì´í„° ì†ìƒì— ëŒ€í•´ ë‹¤ë£¨ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³¼ ê²ƒì´ê³  ì²« ë²ˆì§¸ëŠ” Benchmarking Neural Network Robustness to Common Corruptions and Perturbationsì´ë‹¤. 
ì—¬ê¸°ì„œ ë§í•˜ëŠ” Corruptionsê³¼ Perturbationsì€ adversarial exampleì—ì„œì˜ ì˜ë¯¸ì™€ëŠ” ë‹¤ë¥´ë‹¤. Perturbationsì€ ê³µê²©ìê°€ ì˜ë„ì ìœ¼ë¡œ ë§Œë“  Perturbationsì´ ì•„ë‹ˆë¼ ìì—°ì ìœ¼ë¡œ ë°œìƒí•  ìˆ˜ ìˆëŠ” Perturbationsì„ ì˜ë¯¸í•˜ê³  Corruptionsì€ ì´ë¯¸ì§€ì˜ ì¡°ë„, ë‚ ì”¨ ë“±ì˜ ì˜í–¥ìœ¼ë¡œ ì¸í•œ Corruptionsì„ ì˜ë¯¸í•œë‹¤.   

ìš°ì„  Deep-learning modelì˜ robustnessëŠ” í¬ê²Œ 2ê°€ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ì—°êµ¬ê°€ ì§„í–‰ ì¤‘ì´ë‹¤. ì²« ë²ˆì¬ëŠ” Worst-case adversarial perturbationìœ¼ë¡œ ì´ëŠ” ë§ ê·¸ëŒ€ë¡œ ëª¨ë¸ì˜ Lossë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” adversarial perturbationì„ ì–´ë–»ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ”ì§€, ê·¸ë¦¬ê³  ì–´ë–»ê²Œ robustnessí•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•´ ì—°êµ¬í•˜ëŠ” ë¶„ì•¼ì´ë‹¤. ê·¸ë˜ì„œ ì´ëŠ” ì•ì„œ ë‹¤ë£¬ adversarial exampleì— ëŒ€í•œ ì—°êµ¬ë¼ í•  ìˆ˜ ìˆê³  ê¸°ì¡´ ì—°êµ¬ëŠ” ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ robustnessì— ì´ˆì ì´ ë§ì¶”ì–´ì¡Œì—ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ ì´ˆì ì„ ë‘ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ Common corruptions and perturbationì´ë‹¤. ì´ëŠ” ì¼ë°˜ì ì¸ ìƒí™©ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” corruptionsê³¼ perturbationì— ëŒ€í•œ robustnessë¥¼ ì—°êµ¬í•˜ëŠ” ë¶„ì•¼ì´ë‹¤.                


### Corruption Dataset
<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/aae673d7-1f8f-462e-9b51-2d49cef75bb1" height="70%" width="70%"></p>

ì˜ˆì‹œë“¤ì„ ë³´ë©´ ê°„ë‹¨í•œ ë…¸ì´ì¦ˆë¶€í„° blurí˜„ìƒ Saturate ë“±ì´ ìˆë‹¤. ì´ Robustness Benchmarks ë…¼ë¬¸ì—ì„œëŠ” ìš°ì„  ì–´ë–»ê²Œ ì´ëŸ° ì†ìƒëœ ë°ì´í„°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆëŠ”ì§€ë¶€í„° ì–¸ê¸‰í•œë‹¤. 
ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ê²ƒì€ ImageNet-C benchmarkë¡œ 15ê°œì˜ ì„œë¡œë‹¤ë¥¸ corruptionì„ ê°–ëŠ” ì´ë¯¸ì§€ë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ì„œ validation imagesetì„ êµ¬ì„±í•˜ëŠ” ê²ƒì´ë‹¤. 

ë‹¤ë§Œ ì´ëŸ¬í•œ ì—°êµ¬ë¶„ì•¼ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì ì´ Evaluationì‹œì— ë„¤íŠ¸ì›Œí¬ëŠ” ImageNet-Cì— ëŒ€í•œ datasetì„ ì§ì ‘ì ìœ¼ë¡œ í•™ìŠµë°ì´í„°ë¡œ ì‚¬ìš©í•´ì„œëŠ” ì•ˆëœë‹¤ëŠ” ê²ƒì´ë‹¤. ê¸°ì¡´ì— ê°€ì§€ê³  ìˆëŠ” í•™ìŠµ datasetì— ëŒ€í•´ì„œ ì ì ˆí•˜ê²Œ ìˆ˜ì •í•´ì„œ í•™ìŠµì— ì‚¬ìš©í•˜ê³  ì§ì ‘ì ìœ¼ë¡œ ImageNet-Cì™€ ê°™ì´ ì†ìƒëœ datasetìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ì§€ ì•Šìœ¼ë©´ì„œ test ì‹œì—ëŠ” ImageNet-Cì— ëŒ€í•´ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ê²ƒì´ ëª©í‘œì¸ ê²ƒì´ë‹¤.             

ê·¸ë˜ì„œ Evaluation metricìœ¼ë¡œëŠ” Corrupted Errorë¥¼ ì œì•ˆí•œë‹¤. ì´ëŠ” ê¸°ì¡´ base ëª¨ë¸ì¸ AlexNetê³¼ ë¹„êµí•´ì„œ ì–¼ë§ˆë‚˜ ìš°ìˆ˜í•œì§€ë¥¼ í‰ê°€í•œë‹¤. 

$$CE_c^f = \left(\sum_{s=1}^5 E_{s,c}^f \right) / \left(\sum_{s=1}^5 E_{s,c}^{AlexNet} \right)$$

$c$ : Corruption type  
$s$ : Severity (1 $leq$ s $leq$ 5)  
$E_{s,c}^f$ : Top-1 error of a network $f$   


imagenet datasetìœ¼ë¡œ í•™ìŠµëœ AlexNetì´ ìˆë‹¤ê³  í–ˆì„ ë•Œ AlexNetê³¼ ì •í™•ë„ê°€ ê°™ë‹¤ë©´ 1ì´ ë‚˜ì˜¬ ê²ƒì´ê³ , ë§Œì•½ methodë¥¼ ì ìš©í•˜ì—¬ ë§Œë“  ëª¨ë¸ì´ ë” ì—ëŸ¬ìœ¨ì´ ë‚®ë‹¤ë©´ CEëŠ” 1ë³´ë‹¤ ì‘ì€ ê°’ì´ ë  ê²ƒì´ë‹¤. $c$ëŠ” ì–´ë–¤ ì¢…ë¥˜ì˜ ì†ìƒì„ ê°€ì ¸ì˜¬ì§€ë¥¼ ì •í•˜ê³ , $s$ëŠ” ì†ìƒ ì •ë„ë¥¼ ì–¼ë§ˆë‚˜ ì‹¬í•˜ê²Œ í• ì§€ë¥¼ ì •í•œë‹¤. ê·¸ë˜ì„œ ëª¨ë“  Corruption typeê³¼ Severity caseì— ëŒ€í•´ Top-1 errorì˜ í‰ê·  ê°’ì„ êµ¬í•˜ê³  ì´ë¥¼ AlexNetê³¼ ë¹„êµí•´ ìƒëŒ€ì ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ìš°ìˆ˜í•œì§€ë¥¼ í‰ê°€í•œë‹¤.  

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/721766f6-6255-4e58-8ca9-c9d5a284dfce" height="70%" width="70%"></p>

SeverityëŠ” ìœ„ì²˜ëŸ¼ 5ë‹¨ê³„ë¡œ ìˆì–´ì„œ Severityê°€ ë‚®ì€ ê°’ë¶€í„° ë†’ì€ ê°’ê¹Œì§€ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ê¸°ì— ìš©ì´í•˜ë‹¤. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/38ef3876-c11b-40f8-9757-7759686c425f" height="70%" width="70%"></p>

ê·¸ë¦¬ê³  ë°œìƒí•  ìˆ˜ ìˆëŠ” ë°ì´í„° ì†ìƒ íƒ€ì…ìœ¼ë¡œëŠ” ìœ„ì™€ ê°™ì´ í¬ê²Œ 4ê°€ì§€ë¡œ ë‚˜ëˆˆë‹¤. 


### Perturbation Dataset
ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Perturbationì— ëŒ€í•´ì„œë„ Robustness Benchmarkë¥¼ ì œì•ˆí•œë‹¤. 

<p align="center"><img src="https://github.com/em-1001/AI/assets/80628552/e927b349-8694-4d39-885f-8d205fcd8365" height="35%" width="35%"></p>

ìœ„ ì‚¬ì§„ì€ time seriesì— ë”°ë¥¸ ì´ë¯¸ì§€ ë³€í™”ì´ë‹¤. ê·¸ë˜ì„œ ê°ê° ì„œë¡œ ë‹¤ë¥¸ Perturbationì„ ì„œì„œíˆ ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. 
ê·¸ë˜ì„œ ì´ëŸ¬í•œ time series sequenceëŠ” 30 frameê¹Œì§€ êµ¬ì„±ë˜ê³  ê° frameì€ ì´ì „ frameì— ëŒ€í•´ Perturbationì„ ê°€í•œ ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. 

ì—¬ê¸°ì„œ ì œì•ˆí•˜ëŠ” Evaluation metricì€ Flip Probabilityì´ë‹¤. ì´ëŠ” ì‰½ê²Œ ë§í•´ ì´ì „ í”„ë ˆì„ê³¼ í˜„ì¬ í”„ë ˆì„ì´ ì„œë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜ë˜ëŠ” ì§€ë¥¼ í‰ê°€í•˜ëŠ” ê²ƒì´ë‹¤. ê·¸ë˜ì„œ ë¶„ë¥˜ ê²°ê³¼ê°€ ë’¤ì§‘íˆëŠ”(flipping)ì¼ì´ ì ì„ìˆ˜ë¡ ìš°ìˆ˜í•˜ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤. 

$$FP_p^f = \frac{1}{m(n-1)} \sum_{i=1}^m \sum_{j=2}^n ğŸ™ (f(x_j^{(i)}) \neq f(x_{j-1}^{(i)})) = ğ•¡_{x \sim S} (f(x_j^{(i)}) \neq f(x_{j-1}^{(i)}))$$

$m$ : The perturbation sequences  
$n$ : The number of frames  
$p$ : Perturbation type  
$S$ : $\left\lbrace x_1^{(i)}, x_2^{(i)}, ..., x_n^{(i)} \right\rbrace_{i=1}^m$

perturbation sequencesì˜ ì´ ê°¯ìˆ˜ê°€ mì´ë¼ê³  í•˜ê³  í•œ sequencesì—ì„œ frameì˜ ìˆ˜ê°€ nì´ë¼ í–ˆì„ ë•Œ ì „ì²´ sequencesë¥¼ ë‹¤ í™•ì¸í•˜ë©´ì„œ ê° sequencesì˜ ëª¨ë“  frameì„ ë³´ëŠ”ë° ì—¬ê¸°ì„œ frameì€ 2ë¶€í„° ì‹œì‘í•´ì•¼ ì´ì „ frameê³¼ ë¹„êµí•  ìˆ˜ ìˆë‹¤. 


# AugMix



# Reference 
## Web Link
https://www.youtube.com/watch?v=TPujPAtsH8A&list=LL  

## Paper 
Benchmarking Neural Network Robustness to Common Corruptions and Perturbations : https://arxiv.org/pdf/1903.12261.pdf  
